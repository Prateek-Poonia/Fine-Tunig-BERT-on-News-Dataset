{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:55:58.221730Z","iopub.execute_input":"2025-05-08T19:55:58.222031Z","iopub.status.idle":"2025-05-08T19:55:58.477548Z","shell.execute_reply.started":"2025-05-08T19:55:58.222009Z","shell.execute_reply":"2025-05-08T19:55:58.476986Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoTokenizer\nimport tensorflow as tf\nimport numpy as np\nfrom transformers import Trainer, TrainingArguments\nfrom transformers import AutoModelForSequenceClassification","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:55:58.479206Z","iopub.execute_input":"2025-05-08T19:55:58.479551Z","iopub.status.idle":"2025-05-08T19:56:24.844650Z","shell.execute_reply.started":"2025-05-08T19:55:58.479531Z","shell.execute_reply":"2025-05-08T19:56:24.844080Z"}},"outputs":[{"name":"stderr","text":"2025-05-08 19:56:07.656070: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746734167.851719      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746734167.907797      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:56:24.845325Z","iopub.execute_input":"2025-05-08T19:56:24.845901Z","iopub.status.idle":"2025-05-08T19:56:24.849599Z","shell.execute_reply.started":"2025-05-08T19:56:24.845861Z","shell.execute_reply":"2025-05-08T19:56:24.848945Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"dataset = load_dataset('ag_news')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:56:24.850384Z","iopub.execute_input":"2025-05-08T19:56:24.851407Z","iopub.status.idle":"2025-05-08T19:56:33.807952Z","shell.execute_reply.started":"2025-05-08T19:56:24.851380Z","shell.execute_reply":"2025-05-08T19:56:33.807421Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aac0a80a3c4341f88ee1586b5a873220"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"104f01c50dc343dca3a44d52d2cc52a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f967fe817eb4cab901c7a1e3dcedf85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c2e930c7b23472f868ad5666056366a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad270e990cd74fc49ee91ff06e7fbe9a"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"from transformers import BertTokenizer, TFBertModel\nfrom transformers import BertTokenizer, TFBertForSequenceClassification\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:56:33.809771Z","iopub.execute_input":"2025-05-08T19:56:33.810006Z","iopub.status.idle":"2025-05-08T19:56:39.937639Z","shell.execute_reply.started":"2025-05-08T19:56:33.809989Z","shell.execute_reply":"2025-05-08T19:56:39.936915Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccfe832a2c7a442bb3d742f0c76ab923"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b2826fe6c914607b9779fdb65f430ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc308655ab214f9498fd3605956d21c8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"079df07d00d24a0ab00a346c93a48c20"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e0f3687d138406597617676c38871c0"}},"metadata":{}},{"name":"stderr","text":"I0000 00:00:1746734198.687913      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\nAll PyTorch model weights were used when initializing TFBertForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:56:39.938524Z","iopub.execute_input":"2025-05-08T19:56:39.938836Z","iopub.status.idle":"2025-05-08T19:56:39.942812Z","shell.execute_reply.started":"2025-05-08T19:56:39.938817Z","shell.execute_reply":"2025-05-08T19:56:39.942076Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"tokenized_datasets = dataset.map(tokenize_function, batched=True)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:56:39.943679Z","iopub.execute_input":"2025-05-08T19:56:39.944069Z","iopub.status.idle":"2025-05-08T19:58:19.434175Z","shell.execute_reply.started":"2025-05-08T19:56:39.944045Z","shell.execute_reply":"2025-05-08T19:58:19.433288Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1cabaf4bd38f4379ba0277cc3941fc85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4201948e201a4737bd58ba1138db80f9"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"tokenized_datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:58:19.435112Z","iopub.execute_input":"2025-05-08T19:58:19.435862Z","iopub.status.idle":"2025-05-08T19:58:19.440408Z","shell.execute_reply.started":"2025-05-08T19:58:19.435835Z","shell.execute_reply":"2025-05-08T19:58:19.439774Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 120000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 7600\n    })\n})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"tokenized_datasets['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:58:19.441201Z","iopub.execute_input":"2025-05-08T19:58:19.441419Z","iopub.status.idle":"2025-05-08T19:58:19.470125Z","shell.execute_reply.started":"2025-05-08T19:58:19.441403Z","shell.execute_reply":"2025-05-08T19:58:19.469484Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'text': \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\",\n 'label': 2,\n 'input_ids': [101,\n  2813,\n  2358,\n  1012,\n  6468,\n  15020,\n  2067,\n  2046,\n  1996,\n  2304,\n  1006,\n  26665,\n  1007,\n  26665,\n  1011,\n  2460,\n  1011,\n  19041,\n  1010,\n  2813,\n  2395,\n  1005,\n  1055,\n  1040,\n  11101,\n  2989,\n  1032,\n  2316,\n  1997,\n  11087,\n  1011,\n  22330,\n  8713,\n  2015,\n  1010,\n  2024,\n  3773,\n  2665,\n  2153,\n  1012,\n  102,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'token_type_ids': [0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0],\n 'attention_mask': [1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  1,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0,\n  0]}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"tokenized_datasets.remove_columns(['text'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:58:19.470788Z","iopub.execute_input":"2025-05-08T19:58:19.471420Z","iopub.status.idle":"2025-05-08T19:58:19.487227Z","shell.execute_reply.started":"2025-05-08T19:58:19.471397Z","shell.execute_reply":"2025-05-08T19:58:19.486621Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 120000\n    })\n    test: Dataset({\n        features: ['label', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 7600\n    })\n})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"tokenized_datasets.set_format('torch')\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import Trainer,TrainingArguments\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:58:19.487964Z","iopub.execute_input":"2025-05-08T19:58:19.488222Z","iopub.status.idle":"2025-05-08T19:58:19.498166Z","shell.execute_reply.started":"2025-05-08T19:58:19.488200Z","shell.execute_reply":"2025-05-08T19:58:19.497479Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels = 4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:58:19.498836Z","iopub.execute_input":"2025-05-08T19:58:19.499054Z","iopub.status.idle":"2025-05-08T19:58:20.165065Z","shell.execute_reply.started":"2025-05-08T19:58:19.499039Z","shell.execute_reply":"2025-05-08T19:58:20.164284Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_args = TrainingArguments(\n    output_dir='./results',        # your output directory\n    run_name='my_experiment_1',    # give a unique name for this run\n    num_train_epochs=5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    \n    save_strategy='epoch',\n    logging_dir='./logs',          # directory for logs\n    logging_steps=10,\n    report_to='none'               # or 'wandb' if using WandB\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:58:20.166320Z","iopub.execute_input":"2025-05-08T19:58:20.166625Z","iopub.status.idle":"2025-05-08T19:58:20.194035Z","shell.execute_reply.started":"2025-05-08T19:58:20.166607Z","shell.execute_reply":"2025-05-08T19:58:20.193337Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"pip install --upgrade datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:58:20.196021Z","iopub.execute_input":"2025-05-08T19:58:20.196262Z","iopub.status.idle":"2025-05-08T19:58:25.191338Z","shell.execute_reply.started":"2025-05-08T19:58:20.196245Z","shell.execute_reply":"2025-05-08T19:58:25.190402Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nCollecting datasets\n  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.16)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.19.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.5.0\n    Uninstalling datasets-3.5.0:\n      Successfully uninstalled datasets-3.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(axis=-1)\n    accuracy = (predictions == labels).astype(float).mean()\n    return {\"accuracy\": accuracy}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:58:25.192446Z","iopub.execute_input":"2025-05-08T19:58:25.192717Z","iopub.status.idle":"2025-05-08T19:58:25.197388Z","shell.execute_reply.started":"2025-05-08T19:58:25.192694Z","shell.execute_reply":"2025-05-08T19:58:25.196782Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"trainer = Trainer(\n    model = model,\n    args = training_args,\n    train_dataset=tokenized_datasets['train'].select(range(3000)),\n    eval_dataset=tokenized_datasets['test'].select(range(3000)),\n    compute_metrics=compute_metrics\n\n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T19:58:25.198154Z","iopub.execute_input":"2025-05-08T19:58:25.198404Z","iopub.status.idle":"2025-05-08T20:02:31.410427Z","shell.execute_reply.started":"2025-05-08T19:58:25.198381Z","shell.execute_reply":"2025-05-08T20:02:31.409581Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1875/1875 04:04, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.337300</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.989500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.593100</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.485500</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.448900</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.652200</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.540800</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.609100</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.327200</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.663500</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.346400</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.416600</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.322800</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.544200</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.568700</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.628800</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.561800</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.562000</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.581100</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.376300</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.379400</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.404800</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.486600</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.314800</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.547200</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.403900</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.619800</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.456300</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.445300</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.359200</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.767700</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.274700</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.512700</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.668000</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.162300</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.510800</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.560200</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.465700</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.190300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.189000</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.277900</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.169800</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.250400</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.331100</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.262300</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.318600</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.322300</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.265200</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.337100</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.306800</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.155700</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.119700</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.288300</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.147800</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.333200</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.494900</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.231000</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.284900</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.378300</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.261800</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.437100</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.311600</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.104100</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.355100</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.498800</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.175700</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.248300</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.074300</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.227300</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.230100</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.259300</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.219200</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.236700</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.216000</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.104600</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.170900</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.272700</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.074800</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.270500</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.017900</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.253700</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.111800</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.189700</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.077700</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.005400</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.118800</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.104300</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.072500</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.124300</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.104300</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.041400</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.047700</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.105400</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.240000</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.177900</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>0.154900</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.078100</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>0.339300</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.097000</td>\n    </tr>\n    <tr>\n      <td>1010</td>\n      <td>0.270700</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>0.072500</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>0.090100</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>0.081400</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.342900</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>0.176800</td>\n    </tr>\n    <tr>\n      <td>1070</td>\n      <td>0.099200</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.034500</td>\n    </tr>\n    <tr>\n      <td>1090</td>\n      <td>0.089500</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.232300</td>\n    </tr>\n    <tr>\n      <td>1110</td>\n      <td>0.035000</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>0.005000</td>\n    </tr>\n    <tr>\n      <td>1130</td>\n      <td>0.100100</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>0.048600</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.015000</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>0.109400</td>\n    </tr>\n    <tr>\n      <td>1170</td>\n      <td>0.001600</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>0.062400</td>\n    </tr>\n    <tr>\n      <td>1190</td>\n      <td>0.001700</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.058100</td>\n    </tr>\n    <tr>\n      <td>1210</td>\n      <td>0.017100</td>\n    </tr>\n    <tr>\n      <td>1220</td>\n      <td>0.091100</td>\n    </tr>\n    <tr>\n      <td>1230</td>\n      <td>0.086200</td>\n    </tr>\n    <tr>\n      <td>1240</td>\n      <td>0.020100</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.172200</td>\n    </tr>\n    <tr>\n      <td>1260</td>\n      <td>0.175000</td>\n    </tr>\n    <tr>\n      <td>1270</td>\n      <td>0.086400</td>\n    </tr>\n    <tr>\n      <td>1280</td>\n      <td>0.015300</td>\n    </tr>\n    <tr>\n      <td>1290</td>\n      <td>0.154200</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.004100</td>\n    </tr>\n    <tr>\n      <td>1310</td>\n      <td>0.001400</td>\n    </tr>\n    <tr>\n      <td>1320</td>\n      <td>0.168700</td>\n    </tr>\n    <tr>\n      <td>1330</td>\n      <td>0.029100</td>\n    </tr>\n    <tr>\n      <td>1340</td>\n      <td>0.064800</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.005600</td>\n    </tr>\n    <tr>\n      <td>1360</td>\n      <td>0.109600</td>\n    </tr>\n    <tr>\n      <td>1370</td>\n      <td>0.073900</td>\n    </tr>\n    <tr>\n      <td>1380</td>\n      <td>0.141700</td>\n    </tr>\n    <tr>\n      <td>1390</td>\n      <td>0.107900</td>\n    </tr>\n    <tr>\n      <td>1400</td>\n      <td>0.151200</td>\n    </tr>\n    <tr>\n      <td>1410</td>\n      <td>0.010400</td>\n    </tr>\n    <tr>\n      <td>1420</td>\n      <td>0.129100</td>\n    </tr>\n    <tr>\n      <td>1430</td>\n      <td>0.068500</td>\n    </tr>\n    <tr>\n      <td>1440</td>\n      <td>0.001800</td>\n    </tr>\n    <tr>\n      <td>1450</td>\n      <td>0.128400</td>\n    </tr>\n    <tr>\n      <td>1460</td>\n      <td>0.075800</td>\n    </tr>\n    <tr>\n      <td>1470</td>\n      <td>0.082600</td>\n    </tr>\n    <tr>\n      <td>1480</td>\n      <td>0.087500</td>\n    </tr>\n    <tr>\n      <td>1490</td>\n      <td>0.002200</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.147900</td>\n    </tr>\n    <tr>\n      <td>1510</td>\n      <td>0.002300</td>\n    </tr>\n    <tr>\n      <td>1520</td>\n      <td>0.010500</td>\n    </tr>\n    <tr>\n      <td>1530</td>\n      <td>0.002500</td>\n    </tr>\n    <tr>\n      <td>1540</td>\n      <td>0.030200</td>\n    </tr>\n    <tr>\n      <td>1550</td>\n      <td>0.037300</td>\n    </tr>\n    <tr>\n      <td>1560</td>\n      <td>0.090900</td>\n    </tr>\n    <tr>\n      <td>1570</td>\n      <td>0.007400</td>\n    </tr>\n    <tr>\n      <td>1580</td>\n      <td>0.031100</td>\n    </tr>\n    <tr>\n      <td>1590</td>\n      <td>0.001300</td>\n    </tr>\n    <tr>\n      <td>1600</td>\n      <td>0.002100</td>\n    </tr>\n    <tr>\n      <td>1610</td>\n      <td>0.016200</td>\n    </tr>\n    <tr>\n      <td>1620</td>\n      <td>0.085300</td>\n    </tr>\n    <tr>\n      <td>1630</td>\n      <td>0.001200</td>\n    </tr>\n    <tr>\n      <td>1640</td>\n      <td>0.001500</td>\n    </tr>\n    <tr>\n      <td>1650</td>\n      <td>0.019000</td>\n    </tr>\n    <tr>\n      <td>1660</td>\n      <td>0.039600</td>\n    </tr>\n    <tr>\n      <td>1670</td>\n      <td>0.026800</td>\n    </tr>\n    <tr>\n      <td>1680</td>\n      <td>0.007100</td>\n    </tr>\n    <tr>\n      <td>1690</td>\n      <td>0.001300</td>\n    </tr>\n    <tr>\n      <td>1700</td>\n      <td>0.051300</td>\n    </tr>\n    <tr>\n      <td>1710</td>\n      <td>0.001400</td>\n    </tr>\n    <tr>\n      <td>1720</td>\n      <td>0.148300</td>\n    </tr>\n    <tr>\n      <td>1730</td>\n      <td>0.023400</td>\n    </tr>\n    <tr>\n      <td>1740</td>\n      <td>0.001300</td>\n    </tr>\n    <tr>\n      <td>1750</td>\n      <td>0.006900</td>\n    </tr>\n    <tr>\n      <td>1760</td>\n      <td>0.009200</td>\n    </tr>\n    <tr>\n      <td>1770</td>\n      <td>0.040400</td>\n    </tr>\n    <tr>\n      <td>1780</td>\n      <td>0.000900</td>\n    </tr>\n    <tr>\n      <td>1790</td>\n      <td>0.034800</td>\n    </tr>\n    <tr>\n      <td>1800</td>\n      <td>0.056700</td>\n    </tr>\n    <tr>\n      <td>1810</td>\n      <td>0.000800</td>\n    </tr>\n    <tr>\n      <td>1820</td>\n      <td>0.047600</td>\n    </tr>\n    <tr>\n      <td>1830</td>\n      <td>0.001200</td>\n    </tr>\n    <tr>\n      <td>1840</td>\n      <td>0.003500</td>\n    </tr>\n    <tr>\n      <td>1850</td>\n      <td>0.000900</td>\n    </tr>\n    <tr>\n      <td>1860</td>\n      <td>0.086600</td>\n    </tr>\n    <tr>\n      <td>1870</td>\n      <td>0.006700</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1875, training_loss=0.20550802924359837, metrics={'train_runtime': 245.4486, 'train_samples_per_second': 61.113, 'train_steps_per_second': 7.639, 'total_flos': 986684175360000.0, 'train_loss': 0.20550802924359837, 'epoch': 5.0})"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-08T20:02:31.411351Z","iopub.execute_input":"2025-05-08T20:02:31.411600Z","iopub.status.idle":"2025-05-08T20:02:43.325828Z","shell.execute_reply.started":"2025-05-08T20:02:31.411579Z","shell.execute_reply":"2025-05-08T20:02:43.325236Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 00:11]\n    </div>\n    "},"metadata":{}},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.5844244956970215,\n 'eval_accuracy': 0.9006666666666666,\n 'eval_runtime': 11.905,\n 'eval_samples_per_second': 251.996,\n 'eval_steps_per_second': 31.499,\n 'epoch': 5.0}"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}